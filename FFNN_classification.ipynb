{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-08T15:21:34.024162Z","iopub.execute_input":"2023-08-08T15:21:34.024668Z","iopub.status.idle":"2023-08-08T15:21:34.039745Z","shell.execute_reply.started":"2023-08-08T15:21:34.024628Z","shell.execute_reply":"2023-08-08T15:21:34.038732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import require modules/packages/libraries\nimport tensorflow as tf \n\nfrom tensorflow import keras \nfrom keras.models import Sequential, Model \nfrom keras.layers import Dense, BatchNormalization, Activation, Input \nfrom keras.utils.np_utils import to_categorical \nfrom keras.callbacks import ReduceLROnPlateau ","metadata":{"execution":{"iopub.status.busy":"2023-08-08T15:21:40.189994Z","iopub.execute_input":"2023-08-08T15:21:40.190385Z","iopub.status.idle":"2023-08-08T15:21:40.196809Z","shell.execute_reply.started":"2023-08-08T15:21:40.190355Z","shell.execute_reply":"2023-08-08T15:21:40.195936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#read the data\ntrainf=pd.read_csv('/kaggle/input/digit-recognizer/train.csv', header='infer')\ntestf=pd.read_csv('/kaggle/input/digit-recognizer/test.csv', header='infer')\n\n#Separate X_train (image) and y_train (class label) and get numpy arrays\ny_train=trainf[\"label\"].values\nX_train=trainf.iloc[:,1:].values\n\n#numpy arrays of test images\nX_test=testf.values\n\n#delete dataframe\ndel trainf, testf\n\n#Check the data type and size\nprint(type(X_train), X_train.shape) #ndarray of size 42K X 784\nprint(type(X_test), X_test.shape) #ndarray of size 28K X 784\nprint(type(y_train), y_train.shape) #ndarray of size 42K","metadata":{"execution":{"iopub.status.busy":"2023-08-08T15:23:42.020770Z","iopub.execute_input":"2023-08-08T15:23:42.021597Z","iopub.status.idle":"2023-08-08T15:23:47.350572Z","shell.execute_reply.started":"2023-08-08T15:23:42.021559Z","shell.execute_reply":"2023-08-08T15:23:47.349160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train=(X_train-127.5)/127.5\nX_test=(X_test-127.5)/127.5\n\n#One-hot encode class labels\ny_train=to_categorical(y_train)\n\nprint(type(y_train), y_train.shape) #Notice the output, y_train is now one-hot encoded\nprint(X_train.dtype, y_train.dtype, X_test.dtype)","metadata":{"execution":{"iopub.status.busy":"2023-08-08T15:24:03.245032Z","iopub.execute_input":"2023-08-08T15:24:03.245438Z","iopub.status.idle":"2023-08-08T15:24:03.484480Z","shell.execute_reply.started":"2023-08-08T15:24:03.245406Z","shell.execute_reply":"2023-08-08T15:24:03.483448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduceLROnPlateau=ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001)","metadata":{"execution":{"iopub.status.busy":"2023-08-08T15:24:23.520994Z","iopub.execute_input":"2023-08-08T15:24:23.521392Z","iopub.status.idle":"2023-08-08T15:24:23.527623Z","shell.execute_reply.started":"2023-08-08T15:24:23.521364Z","shell.execute_reply":"2023-08-08T15:24:23.526258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create model\n\ninp=Input(shape=(784,)) \n\nd1=Dense(units=512)(inp)\nb1=BatchNormalization()(d1)\na1=Activation('relu')(b1)\n\nd2=Dense(units=256)(a1)\nb2=BatchNormalization()(d2)\na2=Activation('relu')(b2)\n\nd3=Dense(units=128)(a2)\nb3=BatchNormalization()(d3)\na3=Activation('relu')(b3)\n\nd4=Dense(units=64)(a3)\nb4=BatchNormalization()(d4)\na4=Activation('relu')(b4)\n\nd5=Dense(units=32)(a4)\nb5=BatchNormalization()(d5)\na5=Activation('relu')(b5)\n\nd6=Dense(units=10)(a5)\nb6=BatchNormalization()(d6)\na6=Activation('softmax')(b6)\n\nffnn=Model(inputs=inp, outputs=a6)\nffnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nffnn.summary()\ntf.keras.utils.plot_model(ffnn)","metadata":{"execution":{"iopub.status.busy":"2023-08-08T15:26:21.383901Z","iopub.execute_input":"2023-08-08T15:26:21.384327Z","iopub.status.idle":"2023-08-08T15:26:21.767409Z","shell.execute_reply.started":"2023-08-08T15:26:21.384293Z","shell.execute_reply":"2023-08-08T15:26:21.766026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#display the model\ntf.keras.utils.plot_model(ffnn)","metadata":{"execution":{"iopub.status.busy":"2023-08-08T15:26:32.280977Z","iopub.execute_input":"2023-08-08T15:26:32.281405Z","iopub.status.idle":"2023-08-08T15:26:32.396125Z","shell.execute_reply.started":"2023-08-08T15:26:32.281370Z","shell.execute_reply":"2023-08-08T15:26:32.394918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fit the model. We are setting number of epochs = 150 and batch_size is 120. validation_split is 0.2 that\n#is 20% data will be used for validation\nffnn.fit(x=X_train, y=y_train, epochs=150, callbacks=[reduceLROnPlateau], batch_size=120, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-08-08T15:26:51.720352Z","iopub.execute_input":"2023-08-08T15:26:51.720738Z","iopub.status.idle":"2023-08-08T15:36:17.033163Z","shell.execute_reply.started":"2023-08-08T15:26:51.720709Z","shell.execute_reply":"2023-08-08T15:36:17.031738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions=ffnn.predict(X_test)\nprint(predictions.shape)\n\npredictions=np.argmax(predictions,axis=1) \nprint(predictions.shape) \n\n\n#read sample_submission.csv in the dataframe. The dataframe will have 2 columns ImageId and Label\nsub=pd.read_csv('/kaggle/input/digit-recognizer/sample_submission.csv', header='infer')\n\nsub[\"Label\"]=predictions\n\nsub.to_csv('submission.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-08T15:36:25.698163Z","iopub.execute_input":"2023-08-08T15:36:25.698615Z","iopub.status.idle":"2023-08-08T15:36:28.867914Z","shell.execute_reply.started":"2023-08-08T15:36:25.698580Z","shell.execute_reply":"2023-08-08T15:36:28.866654Z"},"trusted":true},"execution_count":null,"outputs":[]}]}